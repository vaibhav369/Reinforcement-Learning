{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"contextual_bandits.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"QXAFGftRi77t","colab_type":"code","colab":{}},"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","import tensorflow.contrib.slim as slim\n","import random"],"execution_count":0,"outputs":[]},{"metadata":{"id":"eiegCLlbjLXX","colab_type":"code","colab":{}},"cell_type":"code","source":["num_machines = 3\n","num_levers = 4\n","\n","class ContextualBandit:\n","  \n","  def __init__(self):\n","    self.state = 0\n","    self.bandits = [ [ random.uniform(-2, 2) for lever in range(num_levers) ] for machine in range(num_machines) ]\n","    \n","  def get_bandit(self):\n","    ''' Returns a random state '''\n","    self.state = np.random.randint(0, num_machines)\n","    return self.state\n","  \n","  def pull_arm(self, selected_lever):\n","    # Returns the random reward achieved by pulling selected_lever for machine given by self.state\n","    probability = np.random.normal(loc=0, scale=1, size=None)\n","    return 1 if self.bandits[self.state][selected_lever] > probability else -1"],"execution_count":0,"outputs":[]},{"metadata":{"id":"u1YI6vNrlaLK","colab_type":"code","colab":{}},"cell_type":"code","source":["def to_onehot(num, total_size):\n","  arr = np.zeros(shape=[total_size])\n","  arr[num] = 1\n","  return arr\n","\n","\n","class Agent:\n","  \n","  def __init__(self, lr, s_size,a_size):\n","        #These lines established the feed-forward part of the network. The agent takes a state and produces an action.\n","        self.state_in= tf.placeholder(shape=[1],dtype=tf.int32)\n","        state_in_OH = slim.one_hot_encoding(self.state_in,s_size)\n","        output = slim.fully_connected(state_in_OH,a_size,\\\n","            biases_initializer=None,activation_fn=tf.nn.sigmoid,weights_initializer=tf.ones_initializer())\n","        self.output = tf.reshape(output,[-1])\n","        self.chosen_action = tf.argmax(self.output,0)\n","\n","        #The next six lines establish the training proceedure. We feed the reward and chosen action into the network\n","        #to compute the loss, and use it to update the network.\n","        self.reward_holder = tf.placeholder(shape=[1],dtype=tf.float32)\n","        self.action_holder = tf.placeholder(shape=[1],dtype=tf.int32)\n","        self.responsible_weight = tf.slice(self.output,self.action_holder,[1])\n","        self.loss = -(tf.log(self.responsible_weight)*self.reward_holder)\n","        optimizer = tf.train.GradientDescentOptimizer(learning_rate=lr)\n","        self.update = optimizer.minimize(self.loss)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"02R48cQysyCR","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":6885},"outputId":"2bf8b803-d4d4-42c8-893f-ad493201b8ed","executionInfo":{"status":"ok","timestamp":1535381159586,"user_tz":-330,"elapsed":19138,"user":{"displayName":"Vaibhav Gupta","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s128","userId":"101533172066540342731"}}},"cell_type":"code","source":["tf.reset_default_graph()\n","\n","bandit = ContextualBandit()\n","agent = Agent(lr=0.001, s_size=num_machines, a_size=num_levers)\n","weights = tf.trainable_variables()[0]\n","\n","total_episodes = 10000\n","total_reward = np.zeros([num_machines, num_levers])\n","total_trials = np.zeros([num_machines, num_levers])\n","\n","eps = 0.1\n","\n","init = tf.initialize_all_variables()\n","\n","with tf.Session() as sess:\n","  sess.run(init)\n","  \n","  for episode in range(total_episodes):\n","    state = bandit.get_bandit()\n","    \n","    prob_random_action = random.uniform(0, 1)\n","    if prob_random_action < eps:\n","      action = np.random.randint(0, num_levers)\n","    else:\n","      action = sess.run(agent.chosen_action, feed_dict={agent.state_in: [state]})\n","    \n","    reward = bandit.pull_arm(action)\n","    \n","    sess.run(agent.update, feed_dict={agent.reward_holder: [reward], agent.action_holder: [action], agent.state_in: [state]})\n","    \n","    total_reward[state, action] += reward\n","    total_trials[state, action] += 1\n","    \n","    if episode % 100 == 0:\n","      print('Episode:', episode, 'rewards:')\n","      print(total_reward)\n","  print('Finally agent tried each action so many times')\n","  print(total_trials)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Episode: 0 rewards:\n","[[1. 0. 0. 0.]\n"," [0. 0. 0. 0.]\n"," [0. 0. 0. 0.]]\n","Episode: 100 rewards:\n","[[26.  0. -4.  0.]\n"," [-8. -8. -7. -7.]\n"," [ 0. 30.  2.  1.]]\n","Episode: 200 rewards:\n","[[ 48.   2.  -4.  -1.]\n"," [-15. -15. -15. -15.]\n"," [  0.  57.   2.   1.]]\n","Episode: 300 rewards:\n","[[ 72.   2.  -6.  -2.]\n"," [-23. -23. -23. -23.]\n"," [  0.  86.   2.   1.]]\n","Episode: 400 rewards:\n","[[ 96.   3.  -6.  -5.]\n"," [-30. -31. -31. -30.]\n"," [  0. 108.   3.   2.]]\n","Episode: 500 rewards:\n","[[126.   4.  -7.  -6.]\n"," [-38. -37. -37. -37.]\n"," [  0. 131.   3.  -1.]]\n","Episode: 600 rewards:\n","[[151.   4.  -7.  -8.]\n"," [-45. -45. -44. -45.]\n"," [  0. 159.   5.   0.]]\n","Episode: 700 rewards:\n","[[182.   4.  -7.  -9.]\n"," [-52. -51. -52. -52.]\n"," [  2. 184.   5.   1.]]\n","Episode: 800 rewards:\n","[[207.   3.  -8.  -9.]\n"," [-59. -59. -60. -60.]\n"," [  4. 204.   7.   1.]]\n","Episode: 900 rewards:\n","[[234.   4.  -9.  -9.]\n"," [-70. -71. -70. -69.]\n"," [  3. 226.   7.   1.]]\n","Episode: 1000 rewards:\n","[[259.   4. -10. -10.]\n"," [-77. -77. -77. -76.]\n"," [  4. 254.   8.   3.]]\n","Episode: 1100 rewards:\n","[[289.   4. -10. -10.]\n"," [-83. -83. -84. -83.]\n"," [  4. 285.   9.   3.]]\n","Episode: 1200 rewards:\n","[[319.   7. -12. -10.]\n"," [-91. -91. -92. -91.]\n"," [  4. 301.  10.   5.]]\n","Episode: 1300 rewards:\n","[[350.   9. -12. -11.]\n"," [-96. -95. -96. -96.]\n"," [  4. 328.  12.   4.]]\n","Episode: 1400 rewards:\n","[[ 371.    9.  -12.  -13.]\n"," [-105. -105. -104. -105.]\n"," [   4.  353.   13.    5.]]\n","Episode: 1500 rewards:\n","[[ 393.   10.  -12.  -14.]\n"," [-112. -112. -112. -112.]\n"," [   4.  377.   14.    3.]]\n","Episode: 1600 rewards:\n","[[ 421.   10.  -15.  -14.]\n"," [-120. -120. -120. -120.]\n"," [   4.  401.   13.    3.]]\n","Episode: 1700 rewards:\n","[[ 447.   10.  -15.  -14.]\n"," [-128. -128. -129. -128.]\n"," [   4.  421.   14.    3.]]\n","Episode: 1800 rewards:\n","[[ 468.   10.  -14.  -14.]\n"," [-137. -137. -137. -136.]\n"," [   4.  438.   16.    4.]]\n","Episode: 1900 rewards:\n","[[ 501.   10.  -14.  -15.]\n"," [-145. -144. -145. -144.]\n"," [   5.  459.   16.    3.]]\n","Episode: 2000 rewards:\n","[[ 532.   11.  -16.  -16.]\n"," [-153. -152. -154. -152.]\n"," [   5.  479.   16.    3.]]\n","Episode: 2100 rewards:\n","[[ 557.   12.  -16.  -17.]\n"," [-160. -159. -160. -160.]\n"," [   6.  498.   18.    2.]]\n","Episode: 2200 rewards:\n","[[ 589.   12.  -17.  -21.]\n"," [-167. -167. -167. -166.]\n"," [   6.  509.   19.    3.]]\n","Episode: 2300 rewards:\n","[[ 618.   13.  -19.  -22.]\n"," [-174. -173. -174. -173.]\n"," [   7.  532.   19.    1.]]\n","Episode: 2400 rewards:\n","[[ 653.   13.  -20.  -22.]\n"," [-180. -179. -179. -179.]\n"," [   7.  553.   20.    0.]]\n","Episode: 2500 rewards:\n","[[ 680.   13.  -20.  -22.]\n"," [-187. -187. -187. -187.]\n"," [   6.  572.   21.    1.]]\n","Episode: 2600 rewards:\n","[[ 705.   14.  -21.  -23.]\n"," [-196. -195. -196. -195.]\n"," [   7.  598.   21.    0.]]\n","Episode: 2700 rewards:\n","[[ 740.   15.  -21.  -26.]\n"," [-203. -203. -203. -203.]\n"," [   6.  617.   22.    0.]]\n","Episode: 2800 rewards:\n","[[ 769.   16.  -21.  -27.]\n"," [-213. -213. -213. -213.]\n"," [   6.  636.   24.    0.]]\n","Episode: 2900 rewards:\n","[[ 794.   17.  -22.  -27.]\n"," [-222. -222. -222. -222.]\n"," [   6.  650.   24.    1.]]\n","Episode: 3000 rewards:\n","[[ 827.   17.  -24.  -28.]\n"," [-230. -230. -230. -230.]\n"," [   6.  675.   24.    0.]]\n","Episode: 3100 rewards:\n","[[ 850.   17.  -24.  -28.]\n"," [-237. -237. -238. -237.]\n"," [   7.  695.   24.   -1.]]\n","Episode: 3200 rewards:\n","[[ 880.   17.  -26.  -28.]\n"," [-247. -246. -247. -246.]\n"," [   7.  720.   24.   -1.]]\n","Episode: 3300 rewards:\n","[[ 908.   17.  -27.  -28.]\n"," [-256. -255. -256. -255.]\n"," [   7.  741.   26.    1.]]\n","Episode: 3400 rewards:\n","[[ 936.   19.  -29.  -28.]\n"," [-264. -263. -264. -263.]\n"," [   8.  759.   27.    1.]]\n","Episode: 3500 rewards:\n","[[ 967.   19.  -30.  -27.]\n"," [-272. -271. -272. -272.]\n"," [   8.  786.   27.    0.]]\n","Episode: 3600 rewards:\n","[[ 991.   20.  -32.  -28.]\n"," [-279. -279. -280. -279.]\n"," [   7.  809.   29.    0.]]\n","Episode: 3700 rewards:\n","[[1021.   20.  -32.  -28.]\n"," [-287. -287. -288. -287.]\n"," [   7.  829.   29.    0.]]\n","Episode: 3800 rewards:\n","[[1053.   21.  -33.  -29.]\n"," [-293. -293. -293. -293.]\n"," [   8.  855.   30.    2.]]\n","Episode: 3900 rewards:\n","[[1086.   23.  -33.  -29.]\n"," [-298. -299. -300. -299.]\n"," [   9.  879.   30.    2.]]\n","Episode: 4000 rewards:\n","[[ 1.119e+03  2.300e+01 -3.300e+01 -2.900e+01]\n"," [-3.060e+02 -3.050e+02 -3.060e+02 -3.060e+02]\n"," [ 1.000e+01  8.950e+02  3.200e+01  1.000e+00]]\n","Episode: 4100 rewards:\n","[[1147.   23.  -33.  -31.]\n"," [-313. -312. -313. -312.]\n"," [  10.  927.   32.    0.]]\n","Episode: 4200 rewards:\n","[[ 1.179e+03  2.400e+01 -3.400e+01 -3.100e+01]\n"," [-3.190e+02 -3.190e+02 -3.200e+02 -3.190e+02]\n"," [ 1.000e+01  9.570e+02  3.200e+01 -1.000e+00]]\n","Episode: 4300 rewards:\n","[[ 1.204e+03  2.500e+01 -3.500e+01 -3.400e+01]\n"," [-3.280e+02 -3.280e+02 -3.280e+02 -3.280e+02]\n"," [ 1.000e+01  9.770e+02  3.300e+01 -1.000e+00]]\n","Episode: 4400 rewards:\n","[[1232.   24.  -35.  -36.]\n"," [-335. -335. -335. -334.]\n"," [  11. 1002.   34.   -2.]]\n","Episode: 4500 rewards:\n","[[1251.   24.  -36.  -37.]\n"," [-344. -344. -345. -345.]\n"," [   9. 1023.   34.   -3.]]\n","Episode: 4600 rewards:\n","[[1281.   24.  -38.  -37.]\n"," [-353. -353. -353. -353.]\n"," [   9. 1046.   34.   -2.]]\n","Episode: 4700 rewards:\n","[[1307.   24.  -38.  -37.]\n"," [-362. -361. -362. -361.]\n"," [   9. 1066.   34.   -2.]]\n","Episode: 4800 rewards:\n","[[1340.   25.  -37.  -37.]\n"," [-369. -369. -369. -369.]\n"," [   9. 1090.   35.   -2.]]\n","Episode: 4900 rewards:\n","[[1373.   28.  -36.  -38.]\n"," [-376. -376. -375. -375.]\n"," [   8. 1108.   36.   -2.]]\n","Episode: 5000 rewards:\n","[[1403.   30.  -38.  -40.]\n"," [-383. -382. -382. -382.]\n"," [   7. 1133.   37.   -2.]]\n","Episode: 5100 rewards:\n","[[1431.   30.  -38.  -40.]\n"," [-391. -389. -390. -390.]\n"," [   7. 1158.   38.   -3.]]\n","Episode: 5200 rewards:\n","[[1455.   31.  -38.  -42.]\n"," [-397. -397. -398. -397.]\n"," [   8. 1187.   40.   -5.]]\n","Episode: 5300 rewards:\n","[[1481.   32.  -38.  -43.]\n"," [-403. -402. -404. -403.]\n"," [   8. 1215.   43.   -5.]]\n","Episode: 5400 rewards:\n","[[1515.   34.  -39.  -42.]\n"," [-410. -410. -410. -410.]\n"," [   9. 1242.   45.   -5.]]\n","Episode: 5500 rewards:\n","[[1540.   35.  -39.  -43.]\n"," [-418. -416. -418. -417.]\n"," [   8. 1269.   45.   -5.]]\n","Episode: 5600 rewards:\n","[[1571.   35.  -40.  -43.]\n"," [-423. -423. -424. -422.]\n"," [   6. 1294.   45.   -5.]]\n","Episode: 5700 rewards:\n","[[1599.   35.  -40.  -44.]\n"," [-432. -431. -432. -431.]\n"," [   6. 1319.   46.   -4.]]\n","Episode: 5800 rewards:\n","[[1619.   35.  -40.  -46.]\n"," [-439. -439. -440. -439.]\n"," [   6. 1352.   46.   -4.]]\n","Episode: 5900 rewards:\n","[[1644.   36.  -40.  -46.]\n"," [-448. -448. -448. -447.]\n"," [   5. 1380.   46.   -5.]]\n","Episode: 6000 rewards:\n","[[1679.   36.  -39.  -46.]\n"," [-454. -454. -455. -454.]\n"," [   5. 1406.   46.   -3.]]\n","Episode: 6100 rewards:\n","[[1703.   36.  -41.  -46.]\n"," [-463. -462. -463. -462.]\n"," [   5. 1427.   46.   -3.]]\n","Episode: 6200 rewards:\n","[[1729.   38.  -41.  -48.]\n"," [-471. -471. -471. -470.]\n"," [   4. 1455.   47.   -4.]]\n","Episode: 6300 rewards:\n","[[1761.   37.  -44.  -48.]\n"," [-478. -477. -477. -477.]\n"," [   4. 1477.   48.   -3.]]\n","Episode: 6400 rewards:\n","[[1780.   37.  -45.  -49.]\n"," [-484. -484. -484. -484.]\n"," [   4. 1501.   49.   -2.]]\n","Episode: 6500 rewards:\n","[[1797.   37.  -45.  -48.]\n"," [-495. -494. -495. -494.]\n"," [   4. 1523.   49.    0.]]\n","Episode: 6600 rewards:\n","[[1824.   38.  -45.  -48.]\n"," [-502. -501. -500. -501.]\n"," [   4. 1550.   50.    0.]]\n","Episode: 6700 rewards:\n","[[1853.   40.  -45.  -51.]\n"," [-507. -507. -508. -508.]\n"," [   3. 1575.   50.    0.]]\n","Episode: 6800 rewards:\n","[[1888.   41.  -46.  -51.]\n"," [-515. -515. -515. -514.]\n"," [   5. 1597.   52.    0.]]\n","Episode: 6900 rewards:\n","[[1921.   41.  -46.  -52.]\n"," [-521. -521. -521. -521.]\n"," [   5. 1622.   52.    0.]]\n","Episode: 7000 rewards:\n","[[1946.   41.  -47.  -53.]\n"," [-529. -529. -529. -529.]\n"," [   3. 1648.   53.    0.]]\n","Episode: 7100 rewards:\n","[[ 1.975e+03  4.400e+01 -4.800e+01 -5.400e+01]\n"," [-5.350e+02 -5.350e+02 -5.360e+02 -5.360e+02]\n"," [ 3.000e+00  1.675e+03  5.300e+01 -1.000e+00]]\n","Episode: 7200 rewards:\n","[[ 2.002e+03  4.500e+01 -4.900e+01 -5.700e+01]\n"," [-5.430e+02 -5.420e+02 -5.430e+02 -5.430e+02]\n"," [ 2.000e+00  1.709e+03  5.300e+01 -1.000e+00]]\n","Episode: 7300 rewards:\n","[[ 2.035e+03  4.500e+01 -4.900e+01 -5.900e+01]\n"," [-5.500e+02 -5.500e+02 -5.500e+02 -5.500e+02]\n"," [ 2.000e+00  1.734e+03  5.300e+01  0.000e+00]]\n","Episode: 7400 rewards:\n","[[ 2.059e+03  4.700e+01 -5.000e+01 -5.800e+01]\n"," [-5.580e+02 -5.570e+02 -5.570e+02 -5.570e+02]\n"," [ 2.000e+00  1.754e+03  5.400e+01  2.000e+00]]\n","Episode: 7500 rewards:\n","[[ 2.094e+03  4.800e+01 -5.000e+01 -6.000e+01]\n"," [-5.650e+02 -5.650e+02 -5.650e+02 -5.650e+02]\n"," [ 1.000e+00  1.772e+03  5.400e+01  2.000e+00]]\n","Episode: 7600 rewards:\n","[[ 2.127e+03  4.800e+01 -5.000e+01 -6.200e+01]\n"," [-5.720e+02 -5.720e+02 -5.720e+02 -5.720e+02]\n"," [ 0.000e+00  1.795e+03  5.700e+01  2.000e+00]]\n","Episode: 7700 rewards:\n","[[2151.   48.  -50.  -62.]\n"," [-579. -580. -580. -579.]\n"," [   0. 1822.   57.    3.]]\n","Episode: 7800 rewards:\n","[[ 2.187e+03  4.800e+01 -5.000e+01 -6.200e+01]\n"," [-5.880e+02 -5.880e+02 -5.890e+02 -5.880e+02]\n"," [ 1.000e+00  1.837e+03  5.800e+01  3.000e+00]]\n","Episode: 7900 rewards:\n","[[ 2.213e+03  4.800e+01 -5.000e+01 -6.200e+01]\n"," [-5.960e+02 -5.960e+02 -5.970e+02 -5.960e+02]\n"," [ 2.000e+00  1.864e+03  6.100e+01  2.000e+00]]\n","Episode: 8000 rewards:\n","[[2236.   48.  -53.  -65.]\n"," [-605. -605. -605. -605.]\n"," [   3. 1886.   62.    0.]]\n","Episode: 8100 rewards:\n","[[2266.   48.  -53.  -66.]\n"," [-613. -614. -613. -613.]\n"," [   3. 1909.   63.    0.]]\n","Episode: 8200 rewards:\n","[[ 2.299e+03  4.900e+01 -5.300e+01 -6.600e+01]\n"," [-6.220e+02 -6.210e+02 -6.220e+02 -6.210e+02]\n"," [ 3.000e+00  1.935e+03  6.300e+01 -1.000e+00]]\n","Episode: 8300 rewards:\n","[[ 2.326e+03  4.900e+01 -5.300e+01 -6.700e+01]\n"," [-6.280e+02 -6.290e+02 -6.300e+02 -6.280e+02]\n"," [ 4.000e+00  1.962e+03  6.300e+01 -2.000e+00]]\n","Episode: 8400 rewards:\n","[[ 2.362e+03  5.100e+01 -5.400e+01 -6.700e+01]\n"," [-6.350e+02 -6.360e+02 -6.360e+02 -6.360e+02]\n"," [ 4.000e+00  1.981e+03  6.300e+01 -2.000e+00]]\n","Episode: 8500 rewards:\n","[[ 2.395e+03  5.100e+01 -5.500e+01 -6.800e+01]\n"," [-6.420e+02 -6.420e+02 -6.420e+02 -6.420e+02]\n"," [ 5.000e+00  2.002e+03  6.500e+01 -2.000e+00]]\n","Episode: 8600 rewards:\n","[[2426.   53.  -57.  -68.]\n"," [-650. -650. -651. -650.]\n"," [   6. 2026.   65.   -3.]]\n","Episode: 8700 rewards:\n","[[ 2.460e+03  5.400e+01 -5.700e+01 -6.900e+01]\n"," [-6.580e+02 -6.580e+02 -6.590e+02 -6.580e+02]\n"," [ 6.000e+00  2.051e+03  6.500e+01 -2.000e+00]]\n","Episode: 8800 rewards:\n","[[2495.   55.  -57.  -69.]\n"," [-666. -667. -667. -666.]\n"," [   7. 2070.   65.   -3.]]\n","Episode: 8900 rewards:\n","[[2525.   55.  -58.  -69.]\n"," [-675. -676. -676. -676.]\n"," [   7. 2094.   65.   -3.]]\n","Episode: 9000 rewards:\n","[[2556.   55.  -58.  -69.]\n"," [-683. -684. -683. -683.]\n"," [  11. 2118.   66.   -3.]]\n","Episode: 9100 rewards:\n","[[2590.   56.  -60.  -69.]\n"," [-689. -690. -690. -689.]\n"," [  13. 2145.   67.   -3.]]\n","Episode: 9200 rewards:\n","[[2615.   56.  -60.  -69.]\n"," [-700. -700. -700. -699.]\n"," [  13. 2161.   68.   -4.]]\n","Episode: 9300 rewards:\n","[[ 2.645e+03  5.700e+01 -6.000e+01 -7.000e+01]\n"," [-7.050e+02 -7.060e+02 -7.060e+02 -7.050e+02]\n"," [ 1.400e+01  2.184e+03  6.900e+01 -2.000e+00]]\n","Episode: 9400 rewards:\n","[[ 2.669e+03  5.700e+01 -6.100e+01 -7.000e+01]\n"," [-7.140e+02 -7.150e+02 -7.150e+02 -7.140e+02]\n"," [ 1.500e+01  2.217e+03  7.000e+01 -2.000e+00]]\n","Episode: 9500 rewards:\n","[[ 2.700e+03  5.800e+01 -6.200e+01 -7.100e+01]\n"," [-7.210e+02 -7.220e+02 -7.220e+02 -7.210e+02]\n"," [ 1.500e+01  2.243e+03  7.000e+01 -2.000e+00]]\n","Episode: 9600 rewards:\n","[[2722.   61.  -63.  -72.]\n"," [-731. -731. -731. -731.]\n"," [  14. 2263.   71.   -3.]]\n","Episode: 9700 rewards:\n","[[2761.   61.  -62.  -72.]\n"," [-737. -737. -736. -737.]\n"," [  14. 2282.   71.   -3.]]\n","Episode: 9800 rewards:\n","[[2785.   62.  -61.  -73.]\n"," [-744. -744. -745. -744.]\n"," [  15. 2307.   72.   -3.]]\n","Episode: 9900 rewards:\n","[[ 2.812e+03  6.200e+01 -6.100e+01 -7.300e+01]\n"," [-7.530e+02 -7.520e+02 -7.530e+02 -7.520e+02]\n"," [ 1.600e+01  2.337e+03  7.400e+01 -2.000e+00]]\n","Finally agent tried each action so many times\n","[[3116.   79.   94.   85.]\n"," [ 796.  804.  920.  803.]\n"," [  78. 3056.   77.   92.]]\n"],"name":"stdout"}]},{"metadata":{"id":"hGKvBBrm0CQY","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}